---

title: Experiment Utils


keywords: fastai
sidebar: home_sidebar

summary: "Set of functions to easily perform experiments."
description: "Set of functions to easily perform experiments."
nb_path: "nbs/experiments__utils.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/experiments__utils.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_mask_dfs" class="doc_header"><code>get_mask_dfs</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L43" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_mask_dfs</code>(<strong><code>Y_df</code></strong>, <strong><code>ds_in_val</code></strong>, <strong><code>ds_in_test</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_random_mask_dfs" class="doc_header"><code>get_random_mask_dfs</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L73" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_random_mask_dfs</code>(<strong><code>Y_df</code></strong>, <strong><code>ds_in_test</code></strong>, <strong><code>n_val_windows</code></strong>, <strong><code>n_ds_val_window</code></strong>, <strong><code>n_uids</code></strong>, <strong><code>freq</code></strong>)</p>
</blockquote>
<p>Generates train, test and random validation mask.
Train mask begins by avoiding ds_in_test</p>
<p>Validation mask: 1) samples n_uids unique ids
                 2) creates windows of size n_ds_val_window</p>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>ds_in_test: int
    Number of ds in test.
n_uids: int
    Number of unique ids in validation.
n_val_windows: int
    Number of windows for validation.
n_ds_val_window: int
    Number of ds in each validation window.
periods: int
    ds_in_test multiplier.
freq: str
    string that determines datestamp frequency, used in
    random windows creation.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="scale_data" class="doc_header"><code>scale_data</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L129" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>scale_data</code>(<strong><code>Y_df</code></strong>, <strong><code>X_df</code></strong>, <strong><code>mask_df</code></strong>, <strong><code>normalizer_y</code></strong>, <strong><code>normalizer_x</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_datasets" class="doc_header"><code>create_datasets</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L147" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_datasets</code>(<strong><code>mc</code></strong>, <strong><code>S_df</code></strong>, <strong><code>Y_df</code></strong>, <strong><code>X_df</code></strong>, <strong><code>f_cols</code></strong>, <strong><code>ds_in_test</code></strong>, <strong><code>ds_in_val</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_loaders" class="doc_header"><code>instantiate_loaders</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L228" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_loaders</code>(<strong><code>mc</code></strong>, <strong><code>train_dataset</code></strong>, <strong><code>val_dataset</code></strong>, <strong><code>test_dataset</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_nbeats" class="doc_header"><code>instantiate_nbeats</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L272" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_nbeats</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_esrnn" class="doc_header"><code>instantiate_esrnn</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L310" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_esrnn</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_mqesrnn" class="doc_header"><code>instantiate_mqesrnn</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L345" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_mqesrnn</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_nhits" class="doc_header"><code>instantiate_nhits</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L377" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_nhits</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_autoformer" class="doc_header"><code>instantiate_autoformer</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L417" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_autoformer</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_informer" class="doc_header"><code>instantiate_informer</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L454" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_informer</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_transformer" class="doc_header"><code>instantiate_transformer</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L491" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_transformer</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="instantiate_model" class="doc_header"><code>instantiate_model</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L527" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>instantiate_model</code>(<strong><code>mc</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="predict" class="doc_header"><code>predict</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L538" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>predict</code>(<strong><code>mc</code></strong>, <strong><code>model</code></strong>, <strong><code>trainer</code></strong>, <strong><code>loader</code></strong>, <strong><code>scaler_y</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="model_fit_predict" class="doc_header"><code>model_fit_predict</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L555" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>model_fit_predict</code>(<strong><code>mc</code></strong>, <strong><code>S_df</code></strong>, <strong><code>Y_df</code></strong>, <strong><code>X_df</code></strong>, <strong><code>f_cols</code></strong>, <strong><code>ds_in_val</code></strong>, <strong><code>ds_in_test</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="evaluate_model" class="doc_header"><code>evaluate_model</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L622" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>evaluate_model</code>(<strong><code>mc</code></strong>, <strong><code>loss_function_val</code></strong>, <strong><code>loss_functions_test</code></strong>, <strong><code>S_df</code></strong>, <strong><code>Y_df</code></strong>, <strong><code>X_df</code></strong>, <strong><code>f_cols</code></strong>, <strong><code>ds_in_val</code></strong>, <strong><code>ds_in_test</code></strong>, <strong><code>return_forecasts</code></strong>, <strong><code>save_progress</code></strong>, <strong><code>trials</code></strong>, <strong><code>results_file</code></strong>, <strong><code>loss_kwargs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="hyperopt_tunning" class="doc_header"><code>hyperopt_tunning</code><a href="https://github.com/Nixtla/neuralforecast/tree/main/neuralforecast/experiments/utils.py#L683" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>hyperopt_tunning</code>(<strong><code>space</code></strong>, <strong><code>hyperopt_max_evals</code></strong>, <strong><code>loss_function_val</code></strong>, <strong><code>loss_functions_test</code></strong>, <strong><code>S_df</code></strong>, <strong><code>Y_df</code></strong>, <strong><code>X_df</code></strong>, <strong><code>f_cols</code></strong>, <strong><code>ds_in_val</code></strong>, <strong><code>ds_in_test</code></strong>, <strong><code>return_forecasts</code></strong>, <strong><code>save_progress</code></strong>, <strong><code>results_file</code></strong>, <strong><code>loss_kwargs</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Experiment-Utils-Examples">Experiment Utils Examples<a class="anchor-link" href="#Experiment-Utils-Examples"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">t</span>
<span class="kn">from</span> <span class="nn">neuralforecast.losses.numpy</span> <span class="kn">import</span> <span class="n">mae</span><span class="p">,</span> <span class="n">mape</span><span class="p">,</span> <span class="n">smape</span><span class="p">,</span> <span class="n">rmse</span><span class="p">,</span> <span class="n">pinball_loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span>
<span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span> <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>  

<span class="n">nhits_space</span><span class="o">=</span> <span class="p">{</span><span class="c1"># Architecture parameters</span>
               <span class="s1">&#39;model&#39;</span><span class="p">:</span><span class="s1">&#39;nhits&#39;</span><span class="p">,</span>
               <span class="s1">&#39;mode&#39;</span><span class="p">:</span> <span class="s1">&#39;simple&#39;</span><span class="p">,</span>
               <span class="s1">&#39;n_time_in&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_time_in&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">7</span><span class="o">*</span><span class="mi">24</span><span class="p">]),</span>
               <span class="s1">&#39;n_time_out&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_time_out&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">24</span><span class="p">]),</span>
               <span class="s1">&#39;n_x_hidden&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;n_x_hidden&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
               <span class="s1">&#39;n_s_hidden&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_s_hidden&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
               <span class="s1">&#39;shared_weights&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;shared_weights&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">False</span><span class="p">]),</span>
               <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;activation&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;SELU&#39;</span><span class="p">]),</span>
               <span class="s1">&#39;initialization&#39;</span><span class="p">:</span>  <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;initialization&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">,</span><span class="s1">&#39;he_normal&#39;</span><span class="p">]),</span>
               <span class="s1">&#39;stack_types&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;stack_types&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;identity&#39;</span><span class="p">]]),</span>
               <span class="s1">&#39;n_blocks&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_blocks&#39;</span><span class="p">,</span> <span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">]),</span>
               <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_layers&#39;</span><span class="p">,</span> <span class="p">[</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="p">]),</span>
               <span class="s1">&#39;n_hidden&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_hidden&#39;</span><span class="p">,</span> <span class="p">[</span> <span class="mi">256</span> <span class="p">]),</span>
               <span class="s1">&#39;n_pool_kernel_size&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_pool_kernel_size&#39;</span><span class="p">,</span> <span class="p">[</span> <span class="p">[</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span> <span class="p">]</span> <span class="p">]),</span>
               <span class="s1">&#39;n_freq_downsample&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_freq_downsample&#39;</span><span class="p">,</span> <span class="p">[</span> <span class="p">[</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">1</span> <span class="p">]</span> <span class="p">]),</span> 
               <span class="s1">&#39;pooling_mode&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;pooling_mode&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]),</span>
               <span class="s1">&#39;interpolation_mode&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;interpolation_mode&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]),</span>
               <span class="c1"># Regularization and optimization parameters</span>
               <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;batch_normalization&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">False</span><span class="p">]),</span>
               <span class="s1">&#39;dropout_prob_theta&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;dropout_prob_theta&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
               <span class="s1">&#39;dropout_prob_exogenous&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;dropout_prob_exogenous&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
               <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">5e-4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)),</span>
               <span class="s1">&#39;lr_decay&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;lr_decay&#39;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
               <span class="s1">&#39;n_lr_decays&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_lr_decays&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">]),</span>
               <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">5e-5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)),</span>
               <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;max_epochs&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">]),</span> <span class="c1">#&#39;n_iterations&#39;: hp.choice(&#39;n_iterations&#39;, [10])</span>
               <span class="s1">&#39;max_steps&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]),</span>
               <span class="s1">&#39;early_stop_patience&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;early_stop_patience&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">16</span><span class="p">]),</span>
               <span class="s1">&#39;eval_freq&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;eval_freq&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">50</span><span class="p">]),</span>
               <span class="s1">&#39;loss_train&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;MAE&#39;</span><span class="p">]),</span>
               <span class="s1">&#39;loss_hypar&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;loss_hypar&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]),</span>                
               <span class="s1">&#39;loss_valid&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;loss_valid&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;MAE&#39;</span><span class="p">]),</span> <span class="c1">#[args.val_loss]),</span>
               <span class="s1">&#39;l1_theta&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;l1_theta&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
               <span class="c1"># Data parameters</span>
               <span class="s1">&#39;normalizer_y&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;normalizer_y&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]),</span>
               <span class="s1">&#39;normalizer_x&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;normalizer_x&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;median&#39;</span><span class="p">]),</span>
               <span class="s1">&#39;complete_windows&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;complete_windows&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">False</span><span class="p">]),</span>
               <span class="s1">&#39;frequency&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;frequency&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;H&#39;</span><span class="p">]),</span>
               <span class="s1">&#39;seasonality&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;seasonality&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">24</span><span class="p">]),</span>      
               <span class="s1">&#39;idx_to_sample_freq&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;idx_to_sample_freq&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">24</span><span class="p">]),</span>
               <span class="s1">&#39;val_idx_to_sample_freq&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;val_idx_to_sample_freq&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">24</span><span class="p">]),</span>
               <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">32</span><span class="p">]),</span>
               <span class="s1">&#39;n_windows&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;n_windows&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">256</span><span class="p">]),</span>
               <span class="s1">&#39;random_seed&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;random_seed&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
               <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;device&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">device</span><span class="p">])}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">neuralforecast.data.datasets.epf</span> <span class="kn">import</span> <span class="n">EPF</span><span class="p">,</span> <span class="n">EPFInfo</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NP&#39;</span><span class="p">]</span>

<span class="n">Y_df</span><span class="p">,</span> <span class="n">X_df</span><span class="p">,</span> <span class="n">S_df</span> <span class="o">=</span> <span class="n">EPF</span><span class="o">.</span><span class="n">load_groups</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>

<span class="n">X_df</span> <span class="o">=</span> <span class="n">X_df</span><span class="p">[[</span><span class="s1">&#39;unique_id&#39;</span><span class="p">,</span> <span class="s1">&#39;ds&#39;</span><span class="p">,</span> <span class="s1">&#39;week_day&#39;</span><span class="p">]]</span>
<span class="n">Y_min</span> <span class="o">=</span> <span class="n">Y_df</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>

<span class="n">trials</span> <span class="o">=</span> <span class="n">hyperopt_tunning</span><span class="p">(</span><span class="n">space</span><span class="o">=</span><span class="n">nhits_space</span><span class="p">,</span> <span class="n">hyperopt_max_evals</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">loss_function_val</span><span class="o">=</span><span class="n">mae</span><span class="p">,</span>
                          <span class="n">loss_functions_test</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mae&#39;</span><span class="p">:</span> <span class="n">mae</span><span class="p">,</span> <span class="s1">&#39;rmse&#39;</span><span class="p">:</span> <span class="n">rmse</span><span class="p">},</span>
                          <span class="n">S_df</span><span class="o">=</span><span class="n">S_df</span><span class="p">,</span> <span class="n">Y_df</span><span class="o">=</span><span class="n">Y_df</span><span class="p">,</span> <span class="n">X_df</span><span class="o">=</span><span class="n">X_df</span><span class="p">,</span> <span class="n">f_cols</span><span class="o">=</span><span class="p">[],</span>
                          <span class="n">ds_in_val</span><span class="o">=</span><span class="mi">7</span><span class="o">*</span><span class="mi">24</span><span class="p">,</span> <span class="n">ds_in_test</span><span class="o">=</span><span class="mi">7</span><span class="o">*</span><span class="mi">24</span><span class="p">,</span> <span class="n">return_forecasts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">results_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_kwargs</span><span class="o">=</span><span class="p">{})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>  0%|                                                                                                                                                                 | 0/2 [00:00&lt;?, ?trial/s, best loss=?]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO:hyperopt.tpe:build_posterior_wrapper took 0.007082 seconds
INFO:hyperopt.tpe:TPE using 0 trials
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>===============================================                                                                                                                                                             

activation                                SELU                                                                                                                                                              
batch_normalization                      False
batch_size                                  32
complete_windows                         False
device                                     cpu
dropout_prob_exogenous                0.024711
dropout_prob_theta                    0.309513
early_stop_patience                         16
eval_freq                                   50
frequency                                    H
idx_to_sample_freq                          24
initialization                       he_normal
interpolation_mode                      linear
l1_theta                                     0
learning_rate                         0.000991
loss_hypar                                 0.5
loss_train                                 MAE
loss_valid                                 MAE
lr_decay                              0.409441
max_epochs                                  10
max_steps                                 None
mode                                    simple
model                                    nhits
n_blocks                                (1, 1)
n_freq_downsample                      (24, 1)
n_hidden                                   256
n_layers                                (2, 2)
n_lr_decays                                  3
n_pool_kernel_size                      (4, 1)
n_s_hidden                                   0
n_time_in                                  168
n_time_out                                  24
n_windows                                  256
n_x_hidden                                 7.0
normalizer_x                            median
normalizer_y                              None
pooling_mode                               max
random_seed                               19.0
seasonality                                 24
shared_weights                           False
stack_types               (identity, identity)
val_idx_to_sample_freq                      24
weight_decay                          0.000113
dtype: object
===============================================                                                                                                                                                             

  0%|                                                                                                                                                                 | 0/2 [00:00&lt;?, ?trial/s, best loss=?]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO:root:Train Validation splits

INFO:root:                              ds                    
                             min                 max
unique_id sample_mask                               
NP        0           2018-12-11 2018-12-24 23:00:00
          1           2013-01-01 2018-12-10 23:00:00
INFO:root:
Total data 			52416 time stamps 
Available percentage=100.0, 	52416 time stamps 
Insample  percentage=99.36, 	52080 time stamps 
Outsample percentage=0.64, 	336 time stamps 

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsdataset.py:208: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only
  X.drop([&#39;unique_id&#39;, &#39;ds&#39;], 1, inplace=True)

INFO:root:Train Validation splits

INFO:root:                              ds                    
                             min                 max
unique_id sample_mask                               
NP        0           2013-01-01 2018-12-24 23:00:00
          1           2018-12-11 2018-12-17 23:00:00
INFO:root:
Total data 			52416 time stamps 
Available percentage=100.0, 	52416 time stamps 
Insample  percentage=0.32, 	168 time stamps 
Outsample percentage=99.68, 	52248 time stamps 

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsdataset.py:208: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only
  X.drop([&#39;unique_id&#39;, &#39;ds&#39;], 1, inplace=True)

INFO:root:Train Validation splits

INFO:root:                              ds                    
                             min                 max
unique_id sample_mask                               
NP        0           2013-01-01 2018-12-17 23:00:00
          1           2018-12-18 2018-12-24 23:00:00
INFO:root:
Total data 			52416 time stamps 
Available percentage=100.0, 	52416 time stamps 
Insample  percentage=0.32, 	168 time stamps 
Outsample percentage=99.68, 	52248 time stamps 

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsdataset.py:208: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only
  X.drop([&#39;unique_id&#39;, &#39;ds&#39;], 1, inplace=True)

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:49: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.
  &#34;Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7.&#34;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:148: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.
  f&#34;Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will &#34;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer&#39;s `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f&#34;Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and&#34;

GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs

  | Name  | Type   | Params
---------------------------------
0 | model | _NHITS | 376 K 
---------------------------------
376 K     Trainable params
0         Non-trainable params
376 K     Total params
1.508     Total estimated model params size (MB)
/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  f&#34;The dataloader, {name}, does not have many workers which may be a bottleneck.&#34;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  &#34;See the documentation of nn.Upsample for details.&#34;.format(mode)

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  f&#34;The dataloader, {name}, does not have many workers which may be a bottleneck.&#34;

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsloader.py:47: UserWarning: This class wraps the pytorch `DataLoader` with a special collate function. If you want to use yours simply use `DataLoader`. Removing collate_fn
  &#39;This class wraps the pytorch `DataLoader` with a &#39;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  f&#34;The dataloader, {name}, does not have many workers which may be a bottleneck.&#34;

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>VAL y_true.shape: (7, 24)                                                                                                                                                                                   
VAL y_hat.shape: (7, 24)                                                                                                                                                                                    
  0%|                                                                                                                                                                 | 0/2 [00:01&lt;?, ?trial/s, best loss=?]TEST y_true.shape: (7, 24)                                                                                                                                                                                  
TEST y_hat.shape: (7, 24)                                                                                                                                                                                   
 50%|████████████████████████████████████████████████████████████████████                                                                    | 1/2 [00:01&lt;00:01,  1.28s/trial, best loss: 7.134767055511475]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO:hyperopt.tpe:build_posterior_wrapper took 0.007845 seconds
INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 7.134767
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>===============================================                                                                                                                                                             

activation                                SELU                                                                                                                                                              
batch_normalization                      False
batch_size                                  32
complete_windows                         False
device                                     cpu
dropout_prob_exogenous                0.388624
dropout_prob_theta                    0.131691
early_stop_patience                         16
eval_freq                                   50
frequency                                    H
idx_to_sample_freq                          24
initialization                   glorot_normal
interpolation_mode                      linear
l1_theta                                     0
learning_rate                         0.000614
loss_hypar                                 0.5
loss_train                                 MAE
loss_valid                                 MAE
lr_decay                              0.487297
max_epochs                                  10
max_steps                                 None
mode                                    simple
model                                    nhits
n_blocks                                (1, 1)
n_freq_downsample                      (24, 1)
n_hidden                                   256
n_layers                                (2, 2)
n_lr_decays                                  3
n_pool_kernel_size                      (4, 1)
n_s_hidden                                   0
n_time_in                                  168
n_time_out                                  24
n_windows                                  256
n_x_hidden                                 8.0
normalizer_x                            median
normalizer_y                              None
pooling_mode                               max
random_seed                               11.0
seasonality                                 24
shared_weights                           False
stack_types               (identity, identity)
val_idx_to_sample_freq                      24
weight_decay                          0.000325
dtype: object
===============================================                                                                                                                                                             

 50%|████████████████████████████████████████████████████████████████████                                                                    | 1/2 [00:01&lt;00:01,  1.28s/trial, best loss: 7.134767055511475]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO:root:Train Validation splits

INFO:root:                              ds                    
                             min                 max
unique_id sample_mask                               
NP        0           2018-12-11 2018-12-24 23:00:00
          1           2013-01-01 2018-12-10 23:00:00
INFO:root:
Total data 			52416 time stamps 
Available percentage=100.0, 	52416 time stamps 
Insample  percentage=99.36, 	52080 time stamps 
Outsample percentage=0.64, 	336 time stamps 

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsdataset.py:208: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only
  X.drop([&#39;unique_id&#39;, &#39;ds&#39;], 1, inplace=True)

INFO:root:Train Validation splits

INFO:root:                              ds                    
                             min                 max
unique_id sample_mask                               
NP        0           2013-01-01 2018-12-24 23:00:00
          1           2018-12-11 2018-12-17 23:00:00
INFO:root:
Total data 			52416 time stamps 
Available percentage=100.0, 	52416 time stamps 
Insample  percentage=0.32, 	168 time stamps 
Outsample percentage=99.68, 	52248 time stamps 

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsdataset.py:208: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only
  X.drop([&#39;unique_id&#39;, &#39;ds&#39;], 1, inplace=True)

INFO:root:Train Validation splits

INFO:root:                              ds                    
                             min                 max
unique_id sample_mask                               
NP        0           2013-01-01 2018-12-17 23:00:00
          1           2018-12-18 2018-12-24 23:00:00
INFO:root:
Total data 			52416 time stamps 
Available percentage=100.0, 	52416 time stamps 
Insample  percentage=0.32, 	168 time stamps 
Outsample percentage=99.68, 	52248 time stamps 

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsdataset.py:208: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only
  X.drop([&#39;unique_id&#39;, &#39;ds&#39;], 1, inplace=True)

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:49: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.
  &#34;Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7.&#34;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:148: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.
  f&#34;Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will &#34;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer&#39;s `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f&#34;Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and&#34;

GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs

  | Name  | Type   | Params
---------------------------------
0 | model | _NHITS | 376 K 
---------------------------------
376 K     Trainable params
0         Non-trainable params
376 K     Total params
1.508     Total estimated model params size (MB)
/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  f&#34;The dataloader, {name}, does not have many workers which may be a bottleneck.&#34;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  &#34;See the documentation of nn.Upsample for details.&#34;.format(mode)

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  f&#34;The dataloader, {name}, does not have many workers which may be a bottleneck.&#34;

/Users/fedex/projects/neuralforecast/neuralforecast/data/tsloader.py:47: UserWarning: This class wraps the pytorch `DataLoader` with a special collate function. If you want to use yours simply use `DataLoader`. Removing collate_fn
  &#39;This class wraps the pytorch `DataLoader` with a &#39;

/Users/fedex/opt/miniconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  f&#34;The dataloader, {name}, does not have many workers which may be a bottleneck.&#34;

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>VAL y_true.shape: (7, 24)                                                                                                                                                                                   
VAL y_hat.shape: (7, 24)                                                                                                                                                                                    
 50%|████████████████████████████████████████████████████████████████████                                                                    | 1/2 [00:02&lt;00:01,  1.28s/trial, best loss: 7.134767055511475]TEST y_true.shape: (7, 24)                                                                                                                                                                                  
TEST y_hat.shape: (7, 24)                                                                                                                                                                                   
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02&lt;00:00,  1.20s/trial, best loss: 7.134767055511475]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">neuralforecast.data.datasets.long_horizon</span> <span class="kn">import</span> <span class="n">LongHorizon</span>

<span class="n">Y_df</span><span class="p">,</span> <span class="n">X_df</span><span class="p">,</span> <span class="n">S_df</span> <span class="o">=</span> <span class="n">LongHorizon</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s1">&#39;ETTm2&#39;</span><span class="p">)</span>
<span class="n">Y_df</span> <span class="o">=</span> <span class="n">Y_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#                 &#39;model&#39;:&#39;autoformer&#39;,</span>
<span class="c1">#                 &#39;mode&#39;: &#39;iterate_windows&#39;,</span>
<span class="c1">#                 &#39;seq_len&#39;: hp.choice(&#39;seq_len&#39;, [96]),</span>
<span class="c1">#                 &#39;label_len&#39;: hp.choice(&#39;label_len&#39;, [48]),</span>
<span class="c1">#                 &#39;pred_len&#39;: hp.choice(&#39;pred_len&#39;, [24]),</span>
<span class="c1">#                 &#39;output_attention&#39;: hp.choice(&#39;output_attention&#39;, [False]),</span>
<span class="c1">#                 &#39;enc_in&#39;: hp.choice(&#39;enc_in&#39;, [7]),</span>
<span class="c1">#                 &#39;dec_in&#39;: hp.choice(&#39;dec_in&#39;, [7]),</span>
<span class="c1">#                 &#39;d_model&#39;: hp.choice(&#39;d_model&#39;, [512]),</span>
<span class="c1">#                 &#39;c_out&#39;: hp.choice(&#39;c_out&#39;, [7]),</span>
<span class="c1">#                 &#39;embed&#39;: hp.choice(&#39;embed&#39;, [&#39;timeF&#39;]),</span>
<span class="c1">#                 &#39;freq&#39;: hp.choice(&#39;freq&#39;, [&#39;h&#39;]),</span>
<span class="c1">#                 &#39;dropout&#39;: hp.choice(&#39;dropout&#39;, [0.05]),</span>
<span class="c1">#                 &#39;factor&#39;: hp.choice(&#39;factor&#39;, [1]),</span>
<span class="c1">#                 &#39;n_heads&#39;: hp.choice(&#39;n_heads&#39;, [8]),</span>
<span class="c1">#                 &#39;d_ff&#39;: hp.choice(&#39;d_ff&#39;, [2_048]),</span>
<span class="c1">#                 &#39;moving_avg&#39;: hp.choice(&#39;moving_avg&#39;, [25]),</span>
<span class="c1">#                 &#39;activation&#39;: hp.choice(&#39;activation&#39;, [&#39;gelu&#39;]),</span>
<span class="c1">#                 &#39;e_layers&#39;: hp.choice(&#39;e_layers&#39;, [2]),</span>
<span class="c1">#                 &#39;d_layers&#39;: hp.choice(&#39;d_layers&#39;, [1]),</span>
<span class="c1">#                 # Regularization and optimization parameters</span>
<span class="c1">#                 &#39;learning_rate&#39;: hp.choice(&#39;learning_rate&#39;, [0.001]),</span>
<span class="c1">#                 &#39;lr_decay&#39;: hp.choice(&#39;lr_decay&#39;, [0.5]),</span>
<span class="c1">#                 &#39;n_lr_decays&#39;: hp.choice(&#39;n_lr_decays&#39;, [3]), </span>
<span class="c1">#                 &#39;weight_decay&#39;: hp.choice(&#39;weight_decay&#39;, [0]), </span>
<span class="c1">#                 &#39;max_epochs&#39;: hp.choice(&#39;max_epochs&#39;, [10]),</span>
<span class="c1">#                 &#39;max_steps&#39;: hp.choice(&#39;max_steps&#39;, [None]),</span>
<span class="c1">#                 &#39;early_stop_patience&#39;: hp.choice(&#39;early_stop_patience&#39;, [20]),</span>
<span class="c1">#                 &#39;eval_freq&#39;: hp.choice(&#39;eval_freq&#39;, [50]),</span>
<span class="c1">#                 &#39;loss_train&#39;: hp.choice(&#39;loss&#39;, [&#39;MAE&#39;]),</span>
<span class="c1">#                 &#39;loss_hypar&#39;: hp.choice(&#39;loss_hypar&#39;, [0.5]),                </span>
<span class="c1">#                 &#39;loss_valid&#39;: hp.choice(&#39;loss_valid&#39;, [&#39;MAE&#39;]),</span>
<span class="c1">#                 # Data parameters</span>
<span class="c1">#                 &#39;n_time_in&#39;: hp.choice(&#39;n_time_in&#39;, [96]),</span>
<span class="c1">#                 &#39;n_time_out&#39;: hp.choice(&#39;n_time_out&#39;, [24]),</span>
<span class="c1">#                 &#39;normalizer_y&#39;: hp.choice(&#39;normalizer_y&#39;, [None]),</span>
<span class="c1">#                 &#39;normalizer_x&#39;: hp.choice(&#39;normalizer_x&#39;, [None]),</span>
<span class="c1">#                 &#39;val_idx_to_sample_freq&#39;: hp.choice(&#39;val_idx_to_sample_freq&#39;, [1]),</span>
<span class="c1">#                 &#39;batch_size&#39;: hp.choice(&#39;batch_size&#39;, [32]),</span>
<span class="c1">#                 &#39;random_seed&#39;: hp.choice(&#39;random_seed&#39;, [1])}</span>

<span class="c1"># trials = hyperopt_tunning(space=autoformer_space, hyperopt_max_evals=2, loss_function_val=mae,</span>
<span class="c1">#             loss_functions_test={&#39;mae&#39;: mae, &#39;rmse&#39;: rmse},</span>
<span class="c1">#             S_df=S_df, Y_df=Y_df, X_df=X_df, f_cols=[],</span>
<span class="c1">#             ds_in_val=11520, ds_in_test=11520, return_forecasts=True, save_progress=False, results_file=None, loss_kwargs={})</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

